{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install hydra-core"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXWiy9AjEDSY",
        "outputId": "0d25b986-fa9d-48ed-94ff-aeec014831be"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.10/dist-packages (from hydra-core) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core) (23.2)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.4,>=2.2->hydra-core) (6.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HtAflEiYTv6n"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import logging\n",
        "import subprocess as sp\n",
        "import sys\n",
        "from hydra import utils   #use hydra to control the training configurate to better locate and manage different modules while training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "aAaGcbvdFVhW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChildrenManager:\n",
        "  def __init__(self):\n",
        "    self.children = []\n",
        "    self.failed = False\n",
        "\n",
        "  def add(self, child):\n",
        "    child.rank = len(self.children)\n",
        "    self.children.append(child)\n",
        "\n",
        "  def __enter__(self):\n",
        "    return self\n",
        "\n",
        "  def __exit__(self, exc_type, exc_value, traceback):   #ensure that every child exit in a correct way or they all stopped as required\n",
        "    if exc_value is not None:\n",
        "      logger.error(\"An exception happened while starting workers %r\", exc_value)\n",
        "      self.failed = True\n",
        "    try:\n",
        "      while self.children and not self.failed:\n",
        "        for child in list(self.children):\n",
        "          try:\n",
        "            exitcode = child.wait(0.1)\n",
        "          except sp.TimeoutExpired:\n",
        "            continue\n",
        "          else:\n",
        "            self.children.remove(child)\n",
        "            if exitcode:\n",
        "              logger.error(f\"Worker {child.rank} dies, killing all workers\")\n",
        "    except KeyboardInterrupt:\n",
        "      logger.error(\"Received keyboard interrupt, trying to kill all workers.\")\n",
        "      self.failed = True\n",
        "    for child in self.children:\n",
        "      child.terminate()\n",
        "    if not self.failed:\n",
        "      logger.info(\"All workers completed successfully\")"
      ],
      "metadata": {
        "id": "zbIZV2vyFdC4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def start_ddp_workers(cfg):\n",
        "  import torch as th\n",
        "  log = utils.HydraConfig().hydra.job_lohhing.handlers.file.filename #Obtain information related to the log file path in the program's configuration to determine the location of the log file used when the program is running.\n",
        "  rendezvous_file = Path(cfg.rendezvous_file)\n",
        "  if rendezvous_file.exists():\n",
        "    rendezvous_file.unlink()\n",
        "\n",
        "  world_size = th.cuda.device_count()\n",
        "  if not world_size:\n",
        "    logger.error(\n",
        "        \"DDP is noly availble on GPU. Make sure GPUs are properly configured with cuda.\")\n",
        "    sys.exit(1)\n",
        "  logger.info(f\"Starting {world_size} worker processes for DDP.\")\n",
        "  with ChildrenManager() as manager:\n",
        "    for rank in range(world_size):\n",
        "      kwargs = {}\n",
        "      argv = list(sys.argv)\n",
        "      argv += [f\"world_size={world_size}\", f\"rank={rank}\"]\n",
        "      if rank > 0:\n",
        "        kwargs['stdin'] = sp.DEVNULL\n",
        "        kwargs['stdout'] = sp.DEVNULL\n",
        "        kwargs['stderr'] = sp.DEVNULL\n",
        "        log += f\".{rank}\"\n",
        "        argv.append(\"hydra.job_logging.handlers.file.filename=\" + log)\n",
        "      manager.add(sp.Popen([sys.executable] + argv, cwd=utils.get_original_cwd(), **kwargs))\n",
        "  sys.exit(int(manager.failed))"
      ],
      "metadata": {
        "id": "9bhhV_KxHKdO"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}